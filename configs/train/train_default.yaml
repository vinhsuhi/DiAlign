# Training settings
n_epochs: 100
epoch_iters: 200
batch_size: 8
batch_size_test: 20
eval_samples: 1000
lr: 0.002
clip_grad: null          # float, null to disable
save_model: True
num_workers: 0
progress_bar: True
log_every_n_steps: 20
weight_decay: 1e-12
optimizer: adam # adamw,nadamw,nadam => nadamw for large batches, see http://arxiv.org/abs/2102.06356 for the use of nesterov momentum with large batches
seed: 0